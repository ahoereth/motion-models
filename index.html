<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Alexander Höreth">
  <title>Motion Models for People Tracking</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">Motion Models for People Tracking</h1>
  <h2 class="author">Alexander Höreth</h2>
  <h3 class="date">June 2016, University of Osnabrück</h3>
</section>

<section><section id="introduction" class="titleslide slide level1"><h1>Introduction</h1></section><section id="multiple-cameras..." class="slide level2">
<h1>multiple cameras...</h1>
<p><strong>make motion detection rather straightforward</strong></p>
</section><section id="monocularity" class="slide level2">
<h1>monocularity</h1>
<p>makes things more difficult:</p>
<ul>
<li class="fragment">noise</li>
<li class="fragment">occlusion</li>
<li class="fragment">...</li>
</ul>
<p><strong>we require prior information</strong></p>
</section><section id="prior-models" class="slide level2">
<h1>prior models</h1>
<p>estimate plausible poses using probabilities</p>
<p><br />
<br />
sufficiently general to admit all possible motions<br />
&lt;&gt;<br />
strong enough to resolve ambiguities</p>
</section><section id="state-of-the-art" class="slide level2">
<h1>state of the art</h1>
<p>activity specific models from motion capturing</p>
<p><strong>Problem:</strong> Pose and motion data is extremely high dimensional, difficult to visualize and expensive to compute on.</p>
</section><section id="bayesian-filtering" class="slide level2">
<h1>Bayesian Filtering</h1>
<p>approximate the posterior probability distribution over human poses<br />
or motions given image observations</p>
<p><span class="math inline">\(p(x_{1:t}|z_{1:t}) = p(z_{1:t}|x_{1:t})p(x_{1:t}) / p(z_{1:t})\)</span><br />
states <span class="math inline">\(x_{1:t}\)</span>, observations <span class="math inline">\(z_{1:t}\)</span>, time <span class="math inline">\(t\)</span></p>
</section><section id="high-dimensionality" class="slide level2">
<h1>high dimensionality</h1>
<p>computing the posterior distribution is intractable</p>
<ul>
<li class="fragment">assume state independence <span class="math inline">\(p(z_{1:t}|x_{1:t}) = \prod_{i=1:t}p(z_i|x_i)\)</span></li>
<li class="fragment">assume markov process <span class="math inline">\(p(x_t|x_{1:t-1}) = p(x_t|x_{t-1})\)</span></li>
</ul>
<!-- ----------------------------------------------------------------------- -->
</section></section>
<section><section id="kinematics" class="titleslide slide level1"><h1>Kinematics</h1></section><section id="joint-limits" class="slide level2">
<h1>Joint Limits</h1>
<p>limited range of motion in each joint</p>
<p>detected poses need to satisfy valid biomechanics</p>
<p>can be used to capture plausibility of pose estimates</p>
</section><section id="smooth-motion" class="slide level2">
<h1>Smooth Motion</h1>
<p>every new pose equals the old pose with some added noise<br />
<span class="math inline">\(y_{t+1} = y_{t} + \eta\)</span></p>
<p><span class="math inline">\(y_{t+1} = y_{t} + \kappa(y_t - y_{t-1}) + \eta\)</span></p>
<!-- ----------------------------------------------------------------------- -->
</section></section>
<section><section id="linear-kinematic-models" class="titleslide slide level1"><h1>Linear Kinematic Models</h1></section><section id="pose-data" class="slide level2">
<h1>pose data</h1>
<p>collected using off-line motion capturing</p>
<p><span class="math inline">\(\mathbb{D} = \{y^{(i)}\}_{i=1,...,\mathcal{N}}\)</span><br />
<span class="math inline">\(y^{(i)} \in \mathcal{R}^D\)</span></p>
<p>N poses y each consisting of D joint angles</p>
<p>a motion is a sequence of poses: <span class="math inline">\(m = (y_1,...,y_m)\)</span></p>
</section><section id="pose-space" class="slide level2">
<h1>pose space</h1>
<p>activities exhibit strong regularities</p>
<p><span class="math inline">\(\rightarrow\)</span> data from a single activity is likely to be clustered in high dimension</p>
<p><span class="math inline">\(\rightarrow\)</span> eigen-poses can be constructed for complexity reduction</p>
</section><section id="motion-pca" class="slide level2">
<h1>motion PCA</h1>
<p>linear combination of mean motion and eigen-motions characterized by scalar coefficients</p>
<p><span class="math display">\[m \approx \mu + \Sigma_{j=1 \rightarrow B} x_j b_j\]</span></p>
<figure>
<img src="assets/motioncapture.png" alt="4 subjects, varying speeds, ltr: walking, running, both" /><figcaption>4 subjects, varying speeds, ltr: walking, running, both</figcaption>
</figure>
<!-- ----------------------------------------------------------------------- -->
</section></section>
<section><section id="nonlinear-kinematic-models" class="titleslide slide level1"><h1>Nonlinear Kinematic Models</h1></section><section id="dimensionality-reduction" class="slide level2">
<h1>dimensionality reduction</h1>
<figure>
<img src="assets/letters.jpg" alt="input to nonlinear DR and linear DR" height="200" /><figcaption>input to nonlinear DR and linear DR</figcaption>
</figure>
<p><img src="assets/nldr.jpg" alt="nonlinear DR" height="300" /> <img src="assets/ldr.png" alt="linear DR" height="300" /></p>
</section><section id="motivation" class="slide level2">
<h1>motivation</h1>
<p>periodic motions follow a cyclic trajectory in high dimensionality</p>
<p>linear models require many dimensions to appropriately span the data</p>
<p>nonlinear manifolds can model those structures better</p>
</section><section id="gaussians" class="slide level2">
<h1>gaussians</h1>
<p><br />
<br />
univariate <span class="math inline">\(\rightarrow\)</span> multivariate <span class="math inline">\(\rightarrow\)</span> processes</p>
<p><br />
<br />
[drawings]</p>
</section><section id="gaussian-processes" class="slide level2">
<h1>gaussian processes</h1>
<p><span class="math inline">\(f \sim GP(m, k)\)</span><br />
function <span class="math inline">\(f\)</span> is distributed as a GP with mean function <span class="math inline">\(m\)</span> and covariance function <span class="math inline">\(k\)</span></p>
<p>this is a superset of a gaussian distribution<br />
<span class="math inline">\(f \sim \mathcal{N}(\mu_{1:n}, \sigma_{1:n,1:n})\)</span><br />
<span class="math inline">\(\mu_i = m(x_i)\quad\)</span> <span class="math inline">\(\sigma_{ij} = k(x_i, x_j)\)</span></p>
</section><section id="training-gaussian-processes" class="slide level2">
<h1>training gaussian processes</h1>
<p><span class="math inline">\(k(x,x&#39;) = \alpha exp\left(-\gamma/2 * ||x-x&#39;||^2\right) + \beta \delta(x,x&#39;)\)</span></p>
<p>Hyperparameters <span class="math inline">\(\theta={\alpha, \gamma, \beta}\)</span></p>
<p><span class="math inline">\(p(Y|\{x^{(i)}\}, \theta) = \prod_{d=1:D} (1/((2\pi)^N|K|)^{-1}) exp(-1/2 * y_d^T * K^{-1} y_d)\)</span></p>
<p>training tupels of vectors <span class="math inline">\({(x^{(i)}, y^{(i)})}_{i=1:N}\)</span>, <span class="math inline">\(y_d\)</span> being a vector of every <em>dth</em> element <!--
$f_*|f \sim \mathcal{N}(\mu_* + \sigma_*) --></p>
</section><section id="gp-latent-variable-model" class="slide level2">
<h1>GP Latent Variable Model</h1>
<p>utilizes gaussian processes to predict samples from latent variables</p>
<p>main feature: predictive distribution</p>
<p>unsupervised, we only know the observations and not latent space</p>
<p>optimization happens through evaluating for correct latent space <span class="math inline">\(\rightarrow\)</span> pose space mapping</p>
<p>initialized with broad gaussians</p>
</section><section id="gplvm-demo" class="slide level2">
<h1>GPLVM demo</h1>
<iframe width="640" height="480" src="https://www.youtube.com/embed/DS853uA0u4I?rel=0&amp;start=1940&amp;end=1980&amp;color=white&amp;modestbranding=1&amp;showinfo=0" frameborder="0" allowfullscreen>
</iframe>
</section><section id="gp-dynamical-model" class="slide level2">
<h1>GP Dynamical Model</h1>
<p>GPLVM is sampled from independent training data -- ignores temporal relations</p>
<p>intuition for the latent space got lost because of missing spatial proximity</p>
<p><strong>smooth pose trajectories <span class="math inline">\(\rightarrow\)</span> smooth latent trajectories</strong></p>
<p>required for accurate predictions and tracking</p>
<p>GPDM is initialized using GP prior over latent sequences</p>
<figure>
<img src="assets/gpdm.png" alt="GPDM, ltr: latent training poses, probability, sampling" /><figcaption>GPDM, ltr: latent training poses, probability, sampling</figcaption>
</figure>
</section><section id="gpdm-demo" class="slide level2">
<h1>GPDM demo</h1>
<!-- TODO: this actually is back-constraints -->
<iframe width="640" height="480" src="https://www.youtube.com/embed/DS853uA0u4I?rel=0&amp;start=2320&amp;end=2350&amp;color=white&amp;modestbranding=1&amp;showinfo=0" frameborder="0" allowfullscreen>
</iframe>
</section><section id="gpdm-tracking" class="slide level2">
<h1>GPDM tracking</h1>
<figure>
<img src="assets/gpdm-tracking.png" alt="GPDM tracking with occlusion" /><figcaption>GPDM tracking with occlusion</figcaption>
</figure>
</section><section id="extensions" class="slide level2">
<h1>Extensions</h1>
<h3 id="a-multi-factor-gplvm">a) Multi-Factor GPLVM</h3>
<p>weighted sum over individual models with <em>side information</em> available</p>
<h3 id="b-hierarchical-gplvm">b) Hierarchical GPLVM</h3>
<figure>
<img src="assets/gplvm-hierarchical.png" />
</figure>
</section><section id="hierarchical-gplvm-demo" class="slide level2">
<h1>Hierarchical GPLVM Demo</h1>
<iframe width="640" height="480" src="https://www.youtube.com/embed/DS853uA0u4I?rel=0&amp;start=2735&amp;end=2785&amp;color=white&amp;modestbranding=1&amp;showinfo=0&amp;controls=0" frameborder="0" allowfullscreen>
</iframe>
</section><section id="switching-linear-dynamical-systems" class="slide level2">
<h1>Switching Linear Dynamical Systems</h1>
</section><section id="restricted-boltzmann-machines" class="slide level2">
<h1>Restricted Boltzmann Machines</h1>
<p>2 layers, neurons connected between the layers but not within</p>
<p>visible units represent the observation, hidden units the latent space</p>
<p><img src="assets/rbm-in.png" height="400" /> <img src="assets/rbm-out.png" height="400" /></p>
</section><section id="conditional-rbm" class="slide level2">
<h1>Conditional RBM</h1>
<p>extension of RBMs to handle time-series data</p>
<p>added temporal input and autoregression: past n inputs influence current input and hidden layers</p>
<p>autoregressive weights model short-term temporal structure</p>
<p>hidden units model longer-term, higher level structure</p>
<!-- ----------------------------------------------------------------------- -->
</section></section>
<section><section id="newtonian-models" class="titleslide slide level1"><h1>Newtonian Models</h1></section><section id="physics-potential" class="slide level2">
<h1>physics potential</h1>
<p><span class="math inline">\(M\ddot{y} = f_{joints} + f_{gravity} + f_{contact} + a\quad\)</span> <em>mass <span class="math inline">\(m\)</span>, acceleration <span class="math inline">\(\ddot{y}\)</span>, forces <span class="math inline">\(f\)</span></em></p>
<p>physically plausible motions: e.g. balance or interactions</p>
<p>better generalization: e.g. walking vs. walking while carrying heavy object</p>
<p>no need for a lot motion capture data for training</p>
</section><section id="just-potential" class="slide level2">
<h1>just potential</h1>
<p>while very promising, not yet very well researched</p>
<p>models like this are strongly used in gaming</p>
<figure>
<img src="assets/physics.png" />
</figure>
<!-- ----------------------------------------------------------------------- -->
</section></section>
<section><section id="thank-you-for-your-attention" class="titleslide slide level1"><h1>Thank you for your attention</h1></section><section id="links-references" class="slide level2">
<h1>Links &amp; References</h1>
<p>This: <a href="https://ahoereth.github.io/motion-models">ahoereth.github.io/motion-models</a></p>
<p>All images from <a href="http://www.springer.com/us/book/9780857299963">Visual Analysis of Humans</a> (ch.10) and the respective references</p>
<p>Neil Lawrence on GPLVMs @ Google: <a href="https://youtu.be/DS853uA0u4I">youtu.be/DS853uA0u4I</a></p>
<p>Interactive visualizations by Neil Lawrence: <a href="https://github.com/lawrennd/oxford">github.com/lawrennd/oxford</a><br />
<em>seems to be broken, fixed version available on <a href="github.com/ahoereth/motion-models/tree/lawrennd" class="uri">github.com/ahoereth/motion-models/tree/lawrennd</a></em></p>
</section></section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,
        // Display the page number of the current slide
        slideNumber: false,
        // Push each slide change to the browser history
        history: true,
        // Turns fragments on and off globally
        fragments: false,
        // Enable slide navigation via mouse wheel
        mouseWheel: true,
        // Number of slides away from the current that are visible
        viewDistance: 9000,
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1680,
        height: 1050,

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
